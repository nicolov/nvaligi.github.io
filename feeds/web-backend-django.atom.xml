<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Nicolò Valigi</title><link href="/" rel="alternate"></link><link href="/feeds/web-backend-django.atom.xml" rel="self"></link><id>/</id><updated>2015-12-01T00:00:00+01:00</updated><entry><title>Building static sites with Django</title><link href="/switch-static-site-for-side-projects.html" rel="alternate"></link><published>2015-12-01T00:00:00+01:00</published><author><name>Nicolò Valigi</name></author><id>tag:,2015-12-01:switch-static-site-for-side-projects.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Using Django to build lighting fast static sites that are easy to deploy.&lt;/p&gt;
&lt;p&gt;Technology choices have a way of staying with you when keeping side projects alive for more than a few years. In my case, Django has been great in the development and iteration phases, but deployment has given me more headaches that I would hope for.&lt;/p&gt;
&lt;p&gt;In this post, I'm going to talk about my experience generating, serving and maintaining a faster and more reliable site using a static generator for Django.&lt;/p&gt;
&lt;h2&gt;The project&lt;/h2&gt;
&lt;p&gt;I co-run a marketing site that does around 10k daily hits, with around 100 content-heavy pages available in 10 languages around the world. Ideally, I would want to run this from a single small VPS (1GB ram) without UptimeRobot alerts setting off in the middle of the night.&lt;/p&gt;
&lt;p&gt;While undeniably solid, I felt that the &lt;code&gt;uwsgi&lt;/code&gt; + &lt;code&gt;nginx&lt;/code&gt; stack needed a bit more loving care that I had to give. All things considered, I'd rather be programming rather than writing configuration files or reading logs.&lt;/p&gt;
&lt;p&gt;At the same time, it looks like static site generators are everyone's new favourite open source project (after JS frameworks, of course). I've had good luck with &lt;a href="https://github.com/getpelican/pelican"&gt;Pelican&lt;/a&gt; in the past, but prefer to keep the content in the database, not in a tree of text files.&lt;/p&gt;
&lt;p&gt;That's why I've decided to build a static site alongside Django, keeping the lovely admin interface and saving a lot of work in the process.&lt;/p&gt;
&lt;h2&gt;Creating a static site with Django&lt;/h2&gt;
&lt;p&gt;Luckily, the &lt;a href="https://github.com/mtigas/django-medusa"&gt;django-medusa&lt;/a&gt; app met most of my requirements:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;minimal&lt;/em&gt; code changes are required on Django's side: the same project can be run under &lt;code&gt;uwsgi&lt;/code&gt; or generated as a static tree;&lt;/li&gt;
&lt;li&gt;does its magic by hacking Django's testing machinery, so it doesn't have external dependencies and doesn't need to fire up a web server;&lt;/li&gt;
&lt;li&gt;did I mention I got to reuse dozens of templates, template tags, and database queries?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Implementation details&lt;/h3&gt;
&lt;p&gt;I needed to make sure all arguments were passed in as part of the URL (and not as query parameters). This required a bit of regex magic on the URL definitions. For example, I wanted to have optional trailing fragments with the current page and had to use the horrible:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(r'^cool-page(?:/(?P&amp;lt;page&amp;gt;[0-9]+))?/$')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to make sure that the URLs would be reversed correctly (forgetting the final slash is severely punished by the SEO gods).&lt;/p&gt;
&lt;p&gt;The biggest chore is defining a list of all URLs that should be hit while rendering the site. On the bright side, I consider this a kind of &lt;em&gt;integration testing&lt;/em&gt; of the database, views, and template layers.&lt;/p&gt;
&lt;p&gt;Most URL definitions will use &lt;code&gt;django.core.urlresolvers.reverse_lazy&lt;/code&gt; to refer to names paths in the &lt;code&gt;urls.py&lt;/code&gt; module. For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class FixedPages(DiskStaticSiteRenderer):

    def get_paths(self):
        return set([
            reverse_lazy('index'),
            reverse_lazy('about-page'),
            reverse_lazy('top-10')
        ])

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Paginated lists that hit the database are trickier, since the total number of pages is not known in advance, and an additional database query is needed.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def get_paths(slug):
    qs = Article.objects.filter(category__slug=slug)
    pages_range = range(2, (qs.count()-1) // 10 + 2)

    return set([
        [rev('category_list', args=(slug, page)) for page in pages_range] +
        [rev('category_list', args=(slug,))]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I've done some more hacking to render multiple domains and store the HTMLs in different folders:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from django_medusa.renderers import DiskStaticSiteRenderer

def CustomHostDiskRenderer(DiskStaticSiteRenderer):

    def __init__(self, host_name):
        super(DiskStaticSiteRenderer, self).__init__(self)

        self.http_host = host_name
        self.DEPLOY_DIR = os.path.join(
            settings.MEDUSA_DEPLOY_DIR,
            self.http_host)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;A good choice&lt;/h2&gt;
&lt;p&gt;It now takes around 1 minute to completely rebuild my static site in a few (human) languages, and I've yet to feel the need to set up incremental builds to speed up the process. A few lines in nginx's configuration got me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;crazy speed that will hopefully be appreciated by users and rewarded by Google,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;built-in integration testing since all pages are generated for each deployment,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;freedom from cache invalidation and &lt;code&gt;uwsgi&lt;/code&gt; configuration headaches, with plenty of free RAM.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While many bigger sites will opt for a static site to scale better under load, I've found these tricks to be useful for smaller side projects as well.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry><entry><title>Domain sharding in Django</title><link href="/domain-sharding-django.html" rel="alternate"></link><published>2015-10-13T00:00:00+02:00</published><author><name>Nicolò Valigi</name></author><id>tag:,2015-10-13:domain-sharding-django.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;It's 2015. Static files should be served by a CDN. Period. This has several advantages, the most obvious being:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it frees up the resources of your main server, both in bandwidth and CPU terms&lt;/li&gt;
&lt;li&gt;since requests to CDN assets are on a different domain, the browser doesn't have to send (useless) cookies with every request&lt;/li&gt;
&lt;li&gt;most CDN providers have datacenters all over the world to make your site &lt;em&gt;more faster&lt;/em&gt; for more users.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In this article, we are going to look at &lt;strong&gt;domain sharding&lt;/strong&gt;, an additional trick to speed up loading of media-heavy sites.&lt;/p&gt;
&lt;h2&gt;Why more is more&lt;/h2&gt;
&lt;p&gt;Once upon a time, when broadband was far on the horizon, browsers used to have a tight ceiling on the maximum numbers of concurrent requests to a single domain (around 2). These days the situation has improved, and mainstream browsers have pushed this limit up to around 7-8. However, there's still room for improvement by letting browsers load assets from different domains, thus lifting the actual &lt;em&gt;global&lt;/em&gt; connection limit and having your media downloads saturate the user's connection.&lt;/p&gt;
&lt;h2&gt;Doing it in Django&lt;/h2&gt;
&lt;p&gt;While not part of the many batteries included with Django, sharding of media files is pretty easy to implement. There's actually a &lt;a href="https://github.com/coagulant/django-webperf"&gt;project&lt;/a&gt; on Github with a nice implementations a a custom &lt;code&gt;Storage&lt;/code&gt;. Unfortunately, I had some issues when using it other 3rd party modules. Anyhow, I'm posting a slightly revised version which is friendlier and uses inheritance on the &lt;code&gt;__init__&lt;/code&gt; function.&lt;/p&gt;
&lt;script src="https://gist.github.com/nicolov/7d993cc12203e7b81e08.js"&gt;&lt;/script&gt;
&lt;p&gt;As a side note, I'm also using the &lt;code&gt;easy_thumbnails&lt;/code&gt; module for, you guessed it, thumbnails, and also had to set the &lt;code&gt;THUMBNAIL_DEFAULT_STORAGE&lt;/code&gt; variable in &lt;code&gt;settings.py&lt;/code&gt; to make sharding work for images.&lt;/p&gt;
&lt;h2&gt;Mobile, be aware&lt;/h2&gt;
&lt;p&gt;Some recent articles suggest that excessive reliance on domain sharding may actually be detrimental for mobile users due to the behaviour of mobile networks. Have a look &lt;a href="http://www.mobify.com/blog/domain-sharding-bad-news-mobile-performance/"&gt;here&lt;/a&gt; if your website has many visitors on 3/4G networks.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry><entry><title>SQLAlchemy queries in Django</title><link href="/sql-alchemy-queries-in-django.html" rel="alternate"></link><published>2015-10-02T00:00:00+02:00</published><author><name>Nicolò Valigi</name></author><id>tag:,2015-10-02:sql-alchemy-queries-in-django.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Django's ORM is great for 99% of the common web development use cases. Every now and then, however, a bit more flexibility would go a long way and help stay out of the raw SQL rabbit hole. For example, reporting queries are difficult to build with Django's API and could benefit from a little more abstraction.&lt;/p&gt;
&lt;p&gt;In this respect, I believe that SQLAlchemy's &lt;a href="http://docs.sqlalchemy.org/en/latest/core/tutorial.html"&gt;SQL Expression Engine&lt;/a&gt; allows for significant flexibility with neat and reusable code. In this piece, we will look at how to write queries with the Expression Engine and have them executed by Django's DB engine without additional configuration.&lt;/p&gt;
&lt;h2&gt;Integrating Django and SQLAlchemy&lt;/h2&gt;
&lt;p&gt;The great &lt;a href="https://github.com/Deepwalker/aldjemy"&gt;aldjemy&lt;/a&gt; package makes the initial integration painless, and sets up SQLAlchemy to reuse Django's DB connection.&lt;/p&gt;
&lt;p&gt;However, its README focuses on on ORM-style queries using SQLAlchemy's own ORM API. Instead, let's look at how to extract the table information to run our own queries built using the expression engine.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;from aldjemy.core import get_tables, get_engine
from sqlalchemy.sql import select

# for the default DB
engine = get_engine()
# for another DB
engine = get_engine('tracking')

# a dict with DB tables
tables = get_tables()

# each table can now be accessed to build queries:
widgets = tables['widgets']

query = select([
            widget.c.id,
            widget.c.name])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Running the query&lt;/h2&gt;
&lt;p&gt;Since the &lt;code&gt;engine&lt;/code&gt; object is already available, we can just open a connection and run the query:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;conn = engine.connect()
result = conn.execute(query)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an added note, I've found &lt;a href="http://pandas.pydata.org"&gt;Pandas&lt;/a&gt; to be very useful in these kinds of situations. In fact, easy column and row-level operations at the Python level nicely complement the flexibility in data retrieval afforded by SQLAlchemy.&lt;/p&gt;
&lt;p&gt;When using Pandas, fetching the query results into a DataFrame is even easier:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data_frame = pandas.read_sql_query(query, engine)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Under the hood&lt;/h2&gt;
&lt;p&gt;While Django doesn't support connection pooling, it obviously has its own transaction system which is syncronized with the request/response cycle. Aldjemy plugs into this with the &lt;code&gt;core.DjangoPool&lt;/code&gt; class which operates as a SQLAlchemy &lt;code&gt;NullPool&lt;/code&gt; that piggybacks on Django's connections. Each connection is wrapped in a &lt;code&gt;wrapper.Wrapper&lt;/code&gt; to disable SQLAlchemy's handling of transactions and rely on Django's.&lt;/p&gt;
&lt;p&gt;Tables are generated through reflection of Django's models in the &lt;code&gt;tables.generate_tables&lt;/code&gt; function. Aldjemy keeps a mapping of Django field types to SQLAlchemy types and iterates through each model to add the relevant columns to its table.&lt;/p&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;We have seen how to use SQLAlchemy's SQL Expression Language to run complex queries on Django's database without needing to create additional connections or manually define the database schema.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry><entry><title>Continous integration with Django and Protractor</title><link href="/continous-integration-django-protractor.html" rel="alternate"></link><published>2015-06-10T00:00:00+02:00</published><author><name>Nicolò Valigi</name></author><id>tag:,2015-06-10:continous-integration-django-protractor.html</id><summary type="html">&lt;html&gt;&lt;body&gt;&lt;p&gt;Continous integration is a catchy term to refer to the software engineering practice of frequently committing to the &lt;code&gt;master&lt;/code&gt; branch and running automated tests. Failing builds are tagged so that developers can (in theory) immediately drop everything they are doing to fix them.&lt;/p&gt;
&lt;p&gt;Besides the criticisms one could raise from an organizational perspective (a nice analysis is &lt;a href="http://www.yegor256.com/2014/10/08/continuous-integration-is-dead.html"&gt;here&lt;/a&gt;), doing CI right means having a reliable set of automated tests that run with appropriate database-backed data. This is somewhat of a challenge with the modern SPA + REST API setup, since the backend and frontend will each have a different set of unit and integration tests expecting certain rows in the database.&lt;/p&gt;
&lt;p&gt;In this article we are going to look at the popular Django+Angular configuration and lay down an architecture to easily integrate both testing suites (and run them on CircleCI).&lt;/p&gt;
&lt;h2&gt;The problem with Protractor&lt;/h2&gt;
&lt;p&gt;Protractor is the de-facto solution for end-to-end testing of Angular.JS applications. Specifications ("specs") for application behaviour can be written following the Jasmine API and easily run from the command line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;protractor protractor.conf.js --specs="specs/my_spec.js"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem with this setup is that each spec may potentially require a different set of data in the database. Django and DRF (as usual) brilliantly solve the issue by allowing the user to declare a fixture when defining the &lt;code&gt;TestCase&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class ExampleTests(APITestCase):
    fixtures = [...]

    def setUp(self):
        ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at the problem, we see two potential solutions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;script the automated testing so that Django management commands &lt;code&gt;flush&lt;/code&gt; and &lt;code&gt;loaddata&lt;/code&gt; are run before each Protractor spec, creating a new database and loading the necessary data.&lt;/li&gt;
&lt;li&gt;wrap Protractor tests inside a Django management command that sets up a new database, loads the appropriate fixtures, and spawns a Protractor process.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We will be looking at the second approach, for its DRY awesomeness.&lt;/p&gt;
&lt;h2&gt;A Django management command&lt;/h2&gt;
&lt;p&gt;There's an interesting &lt;a href="https://github.com/jpulec/django-protractor"&gt;project on GitHub&lt;/a&gt; offering a tidy Mixin to Django's unit testing classes that spawns a Protractor process with given fixtures. While neat, this is no solution for us because it only ever uses Django's development (and static file) server. I tend to believe that integration tests should be run with as close a configuration to production as possible. In our case, this means that protractor should load the pages through the &lt;em&gt;gunicorn/nginx&lt;/em&gt; stack.&lt;/p&gt;
&lt;p&gt;On the other hand, not having access to Django's testing classes (that automatically set up and tear down new databases) means handling these jobs ourselves. What came out is a management command that takes command line arguments for both django fixtures and protractor specs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python manage.py protractor
    --protractor-conf="protractor/conf.js"
    --fixture="protractor/fixture_a.json"
    --fixture="protractor/fixture_b.json"
    --specs="protractor/spec_1.spec.js"
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Running everything on CircleCI&lt;/h2&gt;
&lt;p&gt;Now that all work has been delegated to the management command, all that needs to be done to run protractor tests in CircleCI is to add lines similar to the one above to the &lt;code&gt;test: override:&lt;/code&gt; array in the circle.yml file. As noted below, please keep in mind that the command does &lt;em&gt;not&lt;/em&gt; support parallel testing, since each process shares the same, single, database (unlike normal Django tests that set up their own databases).&lt;/p&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Thorough testing requires not only a fair number of test cases, but a variety of different situations as well. To solve this issue, we have shown code for a Django management command that wraps protractor processes to load appropriate database fixtures.&lt;/p&gt;
&lt;h2&gt;The code&lt;/h2&gt;
&lt;p&gt;The management command below &lt;strong&gt;flushes&lt;/strong&gt; the database before loading the fixtures requested on the command line. So be careful not to run this on databases with valuable data. The CircleCI VM is obviously fine.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os, sys, subprocess
from multiprocessing import Process
from optparse import make_option

from django.core.management import call_command
from django.core.management.base import BaseCommand
from django.db import connection
from django.conf import settings
from django.test.runner import setup_databases

from south.management.commands import patch_for_test_db_setup

class Command(BaseCommand):
    args = '[--protractor-conf] [--runserver-command] [--specs] [--suite]'

    option_list = BaseCommand.option_list + (
        make_option('--protractor-conf',
            action='store',
            dest='protractor_conf',
            default='protractor.conf.js',
            help='Specify a destination for your protractor configuration'
        ),
        make_option('--specs',
            action='store',
            dest='specs',
            help='Specify which specs to run'
        ),
        make_option('--suite',
            action='store',
            dest='suite',
            help='Specify which suite to run'
        ),
        make_option('--fixture',
            action='append',
            dest='fixtures',
            help='Specify fixture to load initial data to the database'
        ),
    )

    def handle(self, *args, **options):
        options['verbosity'] = int(options.get('verbosity'))

        if not os.path.exists(options['protractor_conf']):
            raise IOError("Could not find '{}'"
                .format(options['protractor_conf']))

        # flush the database
        call_command('flush', verbosity=1, interactive=False)

        fixtures = options['fixtures']
        if fixtures:
            for fixture in fixtures:
                call_command('loaddata', fixture,
                             **{'verbosity': options['verbosity']})

        protractor_command = 'protractor {}'.format(options['protractor_conf'])
        if options['specs']:
            protractor_command += ' --specs {}'.format(options['specs'])
        if options['suite']:
            protractor_command += ' --suite {}'.format(options['suite'])

        self.stdout.write("Running protractor..\n" + protractor_command + "\n")
        return_code = subprocess.call(protractor_command.split())
        sys.exit(return_code)

&lt;/code&gt;&lt;/pre&gt;&lt;/body&gt;&lt;/html&gt;</summary></entry></feed>