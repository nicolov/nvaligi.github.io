<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="//nicolovaligi.com/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="//nicolovaligi.com/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="//nicolovaligi.com/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Nicolò Valigi">
  <meta name="description" content="Posts and writings by Nicolò Valigi">


<meta name="keywords" content="deep learning, keras">

  <title>
Converting a Deep learning model from Caffe to Keras -
    Nicolò Valigi
  </title>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-67820015-1', 'auto');
  ga('send', 'pageview');

</script></head>

<body>
  <aside>
    <div id="user_meta">
      <a href="//nicolovaligi.com">
        <img src="/blog/images/logo_white.jpg" alt="logo">
      </a>
      <h2><a href="//nicolovaligi.com">Nicolò Valigi</a></h2>
      <p>Chronicles of learning.</p>
      <ul class="links">
        <li><a href="//nicolovaligi.com/pages/tutorial-on-robotics-for-developers.html">Tutorial on robotics for developers</a></li>
      </ul>

      <ul style="padding-left: 0;
                 margin-left: -5px;
                 list-style: none;
                 text-align: center;">
        <li>
            <a href="https://github.com/nicolov">
                <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
            </a>
        </li>
        <li>
            <a href="mailto:nicolo.valigi@gmail.com">
                <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                </span>
            </a>
        </li>
    </ul>

    </div>
  </aside>

  <main>
    <header>
      <p>
      <a href="//nicolovaligi.com">Index</a> &nbsp; &brvbar; &nbsp;
      <a href="//nicolovaligi.com/tags.html">Tags</a> &nbsp; &brvbar; &nbsp;
      <a href="//nicolovaligi.com/archives.html">Archives</a>
      </p>
    </header>

<article>
  <div class="article_title">
    <h1><a href="//nicolovaligi.com/converting-deep-learning-model-caffe-keras.html">Converting a Deep learning model from Caffe to Keras</a></h1>
  </div>
  <div class="article_text">
    <p><img alt="Segmenting cat images with Deep Learning" class="img-center" src="//nicolovaligi.com/cat.jpg" style="max-width: 600px"/></p>
<p>A lot of Deep Learning researchers use the <a href="http://caffe.berkeleyvision.org/">Caffe framework</a> to develop new networks and models. I suspect this is at least partly because of the many pre-trained models available in its <a href="https://github.com/albertomontesg/keras-model-zoo">Model Zoo</a>. Using pre-trained weights has several advantages:</p>
<ul>
<li>there's never enough training data around. Niche applications really benefit from pretraining on ImageNet-sized datasets,</li>
<li>training from scratch is slow, expensive, and tricky</li>
</ul>
<p>However, I really can't get behind Caffe's heavy use of protobufs for network definition (<a href="http://stackoverflow.com/questions/5833033/in-lisp-code-is-data-what-benefit-does-that-provide">code <em>is</em> data</a>, after all). This lack of flexibility forces everybody to fork the codebase for minor details, like image preprocessing. And you get to write that in C++, of all things.</p>
<p>I much prefer the approach of TensorFlow and friends, where the computational graph can be built up using the full power of Python functions. This flexibility extends to the pre-processing steps, that are much more reusable when written in a scripting language, outside of the framework code. I usually enjoy working with Keras, since it makes the easy things easy, and the hard things possible (TM).</p>
<p>In this post I will go through the process of converting a pre-trained Caffe network to a Keras model that can be used for inference and fine tuning on different datasets. You can see the end result here: <a href="https://github.com/nicolov/segmentation_keras">Keras DilatedNet</a>. I will assume knowledge of Python and Keras.</p>
<h2>Picking a model for image segmentation</h2>
<p>Lately, I've been researching the state of the art in image segmentation, and came up with a few potential models that I wanted to understand and work on:</p>
<ul>
<li><a href="http://mi.eng.cam.ac.uk/projects/segnet/">SegNet</a> uses a standard Encoder-Decoder network, and also has an interesting Bayesian extension. Pretrained weights on CamVid.</li>
<li><a href="https://github.com/fyu/dilation">DilatedNet</a> does away with the autoencoder structure by adopting <em>dilated</em> convolutions that are provably better for pixel-wise labeling.</li>
<li><a href="https://arxiv.org/pdf/1411.4038.pdf">Fully Convolutional Networks for Semantic Segmentation</a> resembles a classification network, with a single fully-connected layer for the output.</li>
</ul>
<p>I ended up starting my exploration with the second, since it seems to perform better thanks to <em>dilated convolutions</em>, and comes with very clean Caffe code.</p>
<h2>Converting the weights</h2>
<p>Caffe stores weights in <code>*.caffemodel</code> files, which are just serialized Protocol Buffers. We're going to use <a href="https://github.com/ethereon/caffe-tensorflow">caffe-tensorflow</a> to convert these to an HD5 file that can easily be loaded into numpy. The script will convert the <code>.prototxt</code> (network definition) and <code>.caffemodel</code> files to produce weights and a TensorFlow graph.</p>
<div class="highlight"><pre><span></span>python convert.py <span class="se">\</span>
  --caffemodel<span class="o">=</span>~/dilation/pretrained/dilation8_pascal_voc.caffemodel <span class="se">\</span>
  --code-output-path<span class="o">=</span>./pascal_voc_tf/dil8_net.py <span class="se">\</span>
  --data-output-path<span class="o">=</span>./pascal_voc_tf/ <span class="se">\</span>
  ~/dilation/models/dilation8_pascal_voc_deploy.prototxt
</pre></div>
<p>The weights convert fine, but the network doesn't (it's missing a few important details, and won't work as-is). We're going to do it manually for Keras anyways.</p>
<h2>Converting the network definition</h2>
<p>This step is just going to be a rote transcription of the network definition, layer by layer. I've used the <a href="https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069">Keras example</a> for VGG16 and the corresponding <a href="">Caffe definition</a> to get the hang of the process.</p>
<p>For example, this Caffe <code>.prototxt</code>:</p>
<div class="highlight"><pre><span></span><span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">"conv1_2"</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">"Convolution"</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">"conv1_1"</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">"conv1_2"</span>
  <span class="n">convolution_param</span> <span class="p">{</span>
    <span class="n">num_output</span><span class="o">:</span> <span class="mi">64</span>
    <span class="n">kernel_size</span><span class="o">:</span> <span class="mi">3</span>
  <span class="p">}</span>
<span class="p">}</span>
<span class="n">layer</span> <span class="p">{</span>
  <span class="n">name</span><span class="o">:</span> <span class="s">"relu1_2"</span>
  <span class="n">type</span><span class="o">:</span> <span class="s">"ReLU"</span>
  <span class="n">bottom</span><span class="o">:</span> <span class="s">"conv1_2"</span>
  <span class="n">top</span><span class="o">:</span> <span class="s">"conv1_2"</span>
<span class="p">}</span>
</pre></div>
<p>converts to the equivalent Keras:</p>
<div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'conv1_2'</span><span class="p">))</span>
</pre></div>
<p>There's a few things to keep in mind:</p>
<ul>
<li>Keras/Tensorflow stores images in order <em>(rows, columns, channels)</em>, whereas Caffe uses <em>(channels, rows, columns)</em>. <code>caffe-tensorflow</code> automatically fixes the weights, but any preprocessing steps need to as well,</li>
<li>padding is another tricky detail: you can dump the activation of the intermediate layers to make sure that the shapes match at each step</li>
</ul>
<p>Now that the definition is complete, we add some code to load the weights from the HD5 file. By doing it layer-by-layer, new layers can be added at the top without issues:</p>
<div class="highlight"><pre><span></span><span class="n">weights_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">weights_path</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="n">weights_data</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">layer_weights</span> <span class="o">=</span> <span class="n">weights_data</span><span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>

        <span class="n">layer</span><span class="o">.</span><span class="n">set_weights</span><span class="p">((</span><span class="n">layer_weights</span><span class="p">[</span><span class="s1">'weights'</span><span class="p">],</span>
            <span class="n">layer_weights</span><span class="p">[</span><span class="s1">'biases'</span><span class="p">]))</span>
</pre></div>
<p>You don't need to worry about mis-matched shapes, as Keras will throw errors in that case.</p>
<h2>Tips and tricks</h2>
<p>Like any classification problem, semantic segmentation needs a Softmax layer at the top to produce normalized probabilities. In this case, we need <em>pixel-wise</em> softmax, as the network must produce a label for each of the pixels in the image. Since Keras' softmax layer doesn't work on 4D arrays, the pixel data must be reshaped to a 1D vector beforehand. Softmax is applied across the last axis (<em>channels</em>), so its shape (usually) corresponds to the number of classes in the classification. The following code does this:</p>
<div class="highlight"><pre><span></span><span class="n">curr_width</span><span class="p">,</span> <span class="n">curr_height</span><span class="p">,</span> <span class="n">curr_channels</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">output_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Reshape</span><span class="p">((</span><span class="n">curr_width</span><span class="o">*</span><span class="n">curr_height</span><span class="p">,</span> <span class="n">curr_channels</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Activation</span><span class="p">(</span><span class="s1">'softmax'</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Reshape</span><span class="p">((</span><span class="n">curr_width</span><span class="p">,</span> <span class="n">curr_height</span><span class="p">,</span> <span class="n">curr_channels</span><span class="p">)))</span>
</pre></div>
<p>While troubleshooting, it's useful to check the activations at middle layers in the network. As we're only working on the forward pass, we can cut off a part of the Keras <code>Sequential</code> model to look at middle layers. For Caffe's Python wrapper, we can look at the <code>blobs</code> property of the <code>Net</code> object:</p>
<div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span> <span class="n">net</span><span class="o">.</span><span class="n">blobs</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
<h2>Next up: training</h2>
<p>I've uploaded the complete code on <a href="https://github.com/nicolov/segmentation_keras">my Github</a>, where you can check the results using a few of the sample images from the original paper. Now that the inference works, the next step is setting up the training infrastructure to fine-tune the pretrained network on different datasets.</p>
  </div>
  <div class="article_meta">
    <p>Posted on: Sun 20 November 2016</p>
    <p>Category: <a href="//nicolovaligi.com/category/2016-11-20-image-segmentation.html">2016-11-20-image-segmentation</a>
 &ndash; Tags:
      <a href="//nicolovaligi.com/tag/deep-learning.html">deep learning</a>,      <a href="//nicolovaligi.com/tag/keras.html">keras</a>    </p>
  </div>


</article>


    <div id="ending_message">
      <p>&copy; Nicolò Valigi. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme originally by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. </p>
    </div>
  </main>
</body>
</html>