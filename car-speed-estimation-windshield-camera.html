<!DOCTYPE html>
<html lang="en">

<head>
  <!-- ## for client-side less
  <link rel="stylesheet/less" type="text/css" href="http://nicolovaligi.com/theme/css/style.less">
  <script src="http://cdnjs.cloudflare.com/ajax/libs/less.js/1.7.3/less.min.js" type="text/javascript"></script>
  -->
  <link rel="stylesheet" type="text/css" href="http://nicolovaligi.com/theme/css/style.css">
  <link rel="stylesheet" type="text/css" href="http://nicolovaligi.com/theme/css/pygments.css">
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=PT+Sans|PT+Serif|PT+Mono">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="author" content="Nicolò Valigi">
  <meta name="description" content="Posts and writings by Nicolò Valigi">


<meta name="keywords" content="computer vision, self-driving cars">

  <title>
Car speed estimation from a windshield camera -
    Nicolò Valigi
  </title>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-67820015-1', 'auto');
  ga('send', 'pageview');

</script></head>

<body>
  <aside>
    <div id="user_meta">
      <a href="http://nicolovaligi.com">
        <img src="/blog/images/logo_white.jpg" alt="logo">
      </a>
      <h2><a href="http://nicolovaligi.com">Nicolò Valigi</a></h2>
      <p>Software Engineer at Cruise Automation. I write about software and machine learning.</p>
      <ul class="links">
        <li><a href="/pages/robotics-for-developers-tutorial.html">Robotics for developers</a></li>
        <li><a href="/pages/research.html">Research</a></li>
      </ul>

      <ul style="padding-left: 0;
                 margin-left: -5px;
                 list-style: none;
                 text-align: center;">
        <li>
            <a href="https://github.com/nicolov">
                <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                </span>
            </a>
        </li>
        <li>
            <a href="mailto:nicolo.valigi@gmail.com">
                <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                </span>
            </a>
        </li>
    </ul>

    </div>
  </aside>

  <main>
    <header>
      <p>
      <a href="http://nicolovaligi.com">Index</a> &nbsp; &brvbar; &nbsp;
      <a href="http://nicolovaligi.com/tags.html">Tags</a> &nbsp; &brvbar; &nbsp;
      <a href="http://nicolovaligi.com/archives.html">Archives</a>
      </p>
    </header>

<article>
  <div class="article_title">
    <h1><a href="http://nicolovaligi.com/car-speed-estimation-windshield-camera.html">Car speed estimation from a windshield camera</a></h1>
  </div>
  <div class="article_text">
    <p>Measuring the speed of car by capturing images from a windshield camera is a
seemingly easy computer vision problem that actually isn't.</p>
<p>That's because geometry is unforgiving, and a single camera lacks the sense of
depth needed to estimate speed without any assumption about the environment. It
just so happens that humans subconsciously use higher-level visual clues that
help them disambiguate the absolute scale of the scene (i.e. road lanes are a
few metres across).</p>
<p>This post is going to explore a few potential solutions.</p>
<h2>A few alternatives</h2>
<p>One idea would be to leverage decades of research in monocular odometry and
SLAM, and use an open-source package from any research group worldwide. I have
benchmarked a few of those
<a href="http://nicolovaligi.com/open-source-visual-slam-evaluation.html">in a previous post</a>.
<a href="https://github.com/uzh-rpg/rpg_svo">Semi-direct Visual Odometry (SVO)</a>, which I
hadn't mentioned in the article, could also be a good match for this problem.</p>
<p>While all of these approaches start out by detecting interest points across the
image, they differ in the way the recover the camera motion. SLAM packages, such
as ORB or Rovio, explicitly estimate <em>scene structure</em> in the form of a sparse
map of landmarks whose location is found incrementally. Instead, visual odometry
uses concepts from projective geometry, such as the essential matrix, to
estimate the camera motion from feature matches alone.</p>
<p>All of these techniques solve a much more general problem than the one we have
at hand. Not only do they estimate camera velocity, but also its <strong>position</strong>
and 3D orientation. Such power and generality comes at the cost of increased
need for calibration.</p>
<blockquote>
<p>Ideally, we would only need to calibrate the system once (when it's installed
in the car), and <strong>not</strong> every time we start a new trip.</p>
</blockquote>
<p>This requirement rules out any of the monocular SLAM/odometry systems, since
their calibration also depends on the <strong>scene structure</strong>, which is different
for each trip. In other words, the sight of an object on a single camera doesn't
provide any <em>absolute</em> speed information, since its apparent motion in the frame
depends on its distance as well as the camera motion. Using a single camera it's
not possible to disambiguate between these two factors.</p>
<p>Since none of these powerful ideas lends very well to our problem, we're going
to turn to a simpler approach that's easier to specialize for our current task.</p>
<h2>Taking the simple(r) approach</h2>
<p><strong>Optical flow</strong> is one of the most basic concepts in computer vision, and
refers to the apparent motion of objects in the image due to the relative motion
between the camera and the scene. When optical flow is computed for individual
features across the frame, it shows up as <em>vectors</em> that are tangent to the
apparent motion of the feature in the frame. Here's an example:</p>
<p><img alt="Example of optical
flow tracks." class="img-center" src="http://nicolovaligi.com/oflow_sample.jpg" style="max-width: 600px"/></p>
<p>Monocular optical flow suffers from the same ambiguity problems that we
discussed above, and is thus not enough to estimate metric speed. We'll need to
<strong>make more assumptions</strong> about the structure of the scene.</p>
<p>Following the approach in <a href='#Giachetti1999' id='ref-Giachetti1999-1'>Giachetti et al. (1999)</a>, we assume that the car is traveling
over a flat road that can be modeled as a plane. In this particular case, the
two components <span class="math">\(u, v\)</span> of the optical flow at point <span class="math">\((x, y)\)</span> are a quadratic function of
the coordinates themselves:</p>
<div class="math">$$ u = c_{13}x^2 + c_{23}xy + (c_{33} - c_{11})fx - c_{21}fy - c_{31}f^2 $$</div>
<div class="math">$$ v = c_{13}xy + c_{23}y^2 + (c_{33} - c_{22})fy - c_{12}fx - c_{32}f^2 $$</div>
<p>where <span class="math">\(f\)</span> is the focal length of the camera.</p>
<p>We can further simplify these equations by assuming that the road plane is
orthogonal to the camera plane and parallel to its velocity. Both of these
requirements are reasonable in our context. The simplified equations can be
written as:</p>
<div class="math">$$ u = \frac{\omega}{f}x^2 + \frac{V}{hf}xy + \omega f $$</div>
<div class="math">$$ v = \frac{\omega}{f}xy + \frac{V}{hf}y^2 $$</div>
<p>where <span class="math">\(V\)</span> and <span class="math">\(\omega\)</span> are the linear and angular velocities of the camera, and
<span class="math">\(h\)</span> is the distance between the camera and the plane (i.e. road).</p>
<p>Given the sort of test data that I had available, it made sense to discard the
rotational term and only consider the optical flow induced by the translational
velocity. In hindsight, this made sense as errors in the flow estimation vastly
outweighted the small contributions due to camera rotations. That's how the
resulting flow looks like in theory:</p>
<p><img alt="Example of optical
flow tracks." class="img-center" src="http://nicolovaligi.com/flow_example.png" style="max-width: 400px"/></p>
<p>Under this final assumption, we only need ground-truth data to calibrate the
<span class="math">\(hf\)</span> factor, which incorporates the effect of the focal length of the camera and
its height over ground.</p>
<h2>Implementation</h2>
<p>I implemented the tracking and estimation code using OpenCV for the sparse
optical flow function, and a few Numpy functions for the least squares fitting.
It's less than 200 lines that you can find
<a href="https://gist.github.com/nicolov/d010233ea8d35887c6ab47cca97d396f">here</a>.</p>
<p>Due to the assumptions we made when building the model, it's very important to
make sure that we're only looking at the optical flow on road points. Some rough
cropping and masking almost sort-of partially worked on the dataset I had. A
more robust system would use a real image segmentation algorithm to filter out
the road points. Here's an example of the map I've used:</p>
<p><img alt="Example of optical
flow tracks." class="img-center" src="http://nicolovaligi.com/mask.png" style="max-width: 600px; border: 2px solid black;"/></p>
<p>The top rectangle blocks out detection in areas where other cars are likely to
appear, while the area on the right improves estimation quality by discarding
the flow from buildings and other disturbances.</p>
<h2>Results and sticking points</h2>
<p>I used the optical flows from the first 1000 frames together with the ground
truth to fit the <span class="math">\(hf\)</span> factor using least squares. The speed on the following
frames can be then estimated as shown above.</p>
<p>I've tried both mean and median to get rid of noise when going from hundreds of
flow measurements to a single value for the vehicle speed. I've also done some
rough low-passing on the resulting value to smooth out the speed over time (as
expected for a real vehicle).</p>
<p>As you can see below, the results are decent at low speeds, but deteriorate
quite a lot at highway speeds. That's probably due to very bad optical flow
tracking on the highway images, on which very few features were tracked at all.</p>
<p><img alt="Speed estimation results." class="img-center" src="http://nicolovaligi.com/result.png" style="max-width: 600px;"/></p>
<p>I should also implement outlier rejection for the flow vectors, as that should
reduce noise and allow reducing the strength of the low-pass filter to speed up
the dynamic response. Some more improvement ideas are described in <a href='#Barbosa2007' id='ref-Barbosa2007-1'>Barbosa and Silva (2007)</a>.</p>
<p>Again, the code for this lives <a href="https://gist.github.com/nicolov/d010233ea8d35887c6ab47cca97d396f">on Github</a>.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%&#64;#$&#64;#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%&#64;#$&#64;#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script><hr>
<h2>Bibliography</h2>
<p id='Barbosa2007'>R.L Barbosa and J.F.C Silva.
Velocity estimation of a mobile mapping vehicle using filtered monocular optical flow.
<em>… on Mobile Mapping …</em>, pages 2–5, 2007. <a class="cite-backref" href="#ref-Barbosa2007-1" title="Jump back to reference 1">↩</a></p>
<p id='Giachetti1999'>Andrea Giachetti, Marco Campani, and Vincent Torre.
The use of optical flow for road navigation.
<em>IEEE Transactions on Robotics</em>, 1999. <a class="cite-backref" href="#ref-Giachetti1999-1" title="Jump back to reference 1">↩</a></p>

  </div>
  <div class="article_meta">
    <p>Posted on: Tue 01 November 2016</p>
    <p>Category: <a href="http://nicolovaligi.com/category/2016-11-01-speed-estimation.html">2016-11-01-speed-estimation</a>
 &ndash; Tags:
      <a href="http://nicolovaligi.com/tag/computer-vision.html">computer vision</a>,      <a href="http://nicolovaligi.com/tag/self-driving-cars.html">self-driving cars</a>    </p>
  </div>


</article>


    <div id="ending_message">
      <p>&copy; Nicolò Valigi. Built using <a href="http://getpelican.com" target="_blank">Pelican</a>. Theme originally by Giulio Fidente on <a href="https://github.com/gfidente/pelican-svbhack" target="_blank">github</a>. </p>
    </div>
  </main>
</body>
</html>